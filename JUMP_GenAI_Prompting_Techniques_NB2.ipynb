{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hRiY8NNNdgp0"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mandy2324/Gen-AI/blob/main/JUMP_GenAI_Prompting_Techniques_NB2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative AI and Prompt Engineering: Prompting Techniques\n",
        "## Notebook 2: Exploring Techniques"
      ],
      "metadata": {
        "id": "Z9rmbr8eFfHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "SpzuVLSoFtAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code cells below in order. Make sure they are finished running before running the next cell."
      ],
      "metadata": {
        "id": "xkjTbyidHArI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required packages\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "7TzS67P4G6bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dffbe01f-a1a0-486d-96e6-0a5528e2e310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ681leNFV_4"
      },
      "outputs": [],
      "source": [
        "# Importing the required libraries\n",
        "import openai\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accessing the API with your key"
      ],
      "metadata": {
        "id": "4eEOZVxuITPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below, replace the text (making sure to keep the quotes) with your OpenAI API key. If you don't have the key that was given to you when you made the account, you can make a new key easily. Just go to \"View API Keys\" in your account settings and select \"create new secret key\". This will disappear after you make it, so be sure to copy it somewhere safe."
      ],
      "metadata": {
        "id": "k8p701bpIabz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"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\" # Paste your API key from your openAI account here. If you need to, you can make a new one in your user settings on the OpenAI site."
      ],
      "metadata": {
        "id": "kRGiAs3eHgw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing a quick function for querying the model\n"
      ],
      "metadata": {
        "id": "HGuL50yvMUSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write something that we can easily reference when we want to prompt the model. Nothing to add here, but feel free to examine what's happening."
      ],
      "metadata": {
        "id": "rFMeD-G5MXw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cc(prompt, model=\"gpt-3.5-turbo\"):\n",
        "  messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=0.1 # Degree of randomness\n",
        "  )\n",
        "  return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "i9vTzIRcMfYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing out different techniques"
      ],
      "metadata": {
        "id": "8xy9cRoVI26a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the cells below, replace the text in triple quotes (after reading it) with a prompt uitilizing that particular technique. Keep in mind that the API doesn't remember your conversation like ChatGPT does."
      ],
      "metadata": {
        "id": "1hZxIEHQbK3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-shot Prompting"
      ],
      "metadata": {
        "id": "w49eA1S_I8Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Can you tell me how to swim?\n",
        "\"\"\"\n",
        "\n",
        "# Examples:\n",
        "# Can you tell me about the history of the Roman Empire?\n",
        "# Explain the basics of quantum mechanics.\n",
        "\n",
        "\n",
        "response = get_cc(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "MSVnSeGIJLua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "27445328-4617-447f-9a17-eb2bcfe69eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-242ab61c7a53>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_cc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-shot prompting"
      ],
      "metadata": {
        "id": "e_EcoiG2aw-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "coffee: mushroom and expresso\n",
        "\"\"\"\n",
        "\n",
        "# Examples:\n",
        "# Dog: Border Collie, Labrador Retriever,\n",
        "# I need a recipe for Tavern Soup. Here's a similar recipe: <recipe>\n",
        "\n",
        "response = get_cc(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "M7OlkLS5axY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5364a98d-3295-4cc8-d995-db4fc7cbf0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mushroom and espresso coffee is a unique blend that combines the earthy flavors of mushrooms with the boldness of espresso. This type of coffee is made by infusing mushroom extracts or powders into the espresso, resulting in a rich and complex flavor profile.\n",
            "\n",
            "The addition of mushrooms to coffee may seem unusual, but it can offer several benefits. Mushrooms are known for their umami flavor, which can enhance the overall taste of the coffee. They also contain various nutrients and antioxidants that can contribute to a healthier beverage.\n",
            "\n",
            "The mushroom and espresso coffee can have a slightly earthy and nutty taste, with hints of bitterness from the espresso. The flavor can vary depending on the type of mushrooms used and the brewing method. Some popular mushroom varieties used in this type of coffee include lion's mane, chaga, and reishi.\n",
            "\n",
            "In addition to its unique flavor, mushroom and espresso coffee may also have potential health benefits. Certain mushrooms, such as lion's mane and chaga, are believed to have cognitive-enhancing properties and immune-boosting effects. However, more research is needed to fully understand the potential health benefits of mushroom-infused coffee.\n",
            "\n",
            "Overall, mushroom and espresso coffee offers a distinctive and flavorful twist to your regular cup of joe. Whether you're a coffee enthusiast looking for something new or someone interested in exploring the potential health benefits of mushrooms, this blend can be an interesting choice to try.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain-of-Thought Prompting"
      ],
      "metadata": {
        "id": "LGjCkYgEccST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        " 1 + 4 * 5 = 1 + 20 = 21; 4 + 2 * 7 = ?\n",
        "\"\"\"\n",
        "\n",
        "# Example:\n",
        "# 1 + 4 * 5 = 1 + 20 = 21; 4 + 2 * 7 = ?\n",
        "#\n"
      ],
      "metadata": {
        "id": "HHdQ2o8jcmnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-consistency"
      ],
      "metadata": {
        "id": "hRiY8NNNdgp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for something a bit more complicated. Here we're going to generate output from the same prompt multiple times, then we'll examine each response and determine the correct result from the options generated."
      ],
      "metadata": {
        "id": "1jyyefJcdpaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        " 1 + 4 * 5 = 1 + 20 = 21; 4 + 2 * 7 = ?\n",
        "\n",
        "\"\"\"\n",
        "response = get_cc(prompt)\n",
        "print(response)\n",
        "# Example:\n",
        "#"
      ],
      "metadata": {
        "id": "xsSbOtcmeFb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638391d2-ecf9-4c98-a724-d10ce2a50174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 + 2 * 7 = 4 + 14 = 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_1 = \"\"\"\n",
        " 1 + 4 * 5 = 1 + 20 = 21; 4 + 2 * 7 = ?\n",
        "\"\"\"\n",
        "\n",
        "response_2 = \"\"\"\n",
        " 1 + 4 * 5 = 1 + 20 = 21; 4 + 2 * 7 = ?\n",
        "\"\"\"\n",
        "\n",
        "response_3 = \"\"\"\n",
        " 1 + 4 * 5 = 1 + 20 = 21; 4 + 2 * 7 = ?\n",
        "\"\"\"\n",
        "\n",
        "response = get_cc(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "RUgzYeiygM2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea52c313-a03e-496f-ed39-40bd87cb90d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 + 2 * 7 = 4 + 14 = 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now if there are any inconsistencies in the responses, they're easy to see. Compare all 3 responses and write a new response (yourself or via the model) that marginalizes false reasoning paths and consolidates into one truthful answer."
      ],
      "metadata": {
        "id": "9wPMrZd4gYjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generated-knowledge prompting"
      ],
      "metadata": {
        "id": "ki4qvp1LhEDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knowledge = f\"\"\"traverse a binary tree.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"Include {knowledge} here and inquire about the subject.\"\"\"\n",
        "\n",
        "response = get_cc(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "cxWPawQLhHgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7606fc16-c965-4d38-bf28-5f2bb40b48a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To traverse a binary tree means to visit each node in the tree in a specific order. There are three common methods for traversing a binary tree:\n",
            "\n",
            "1. Inorder Traversal: In this traversal, we first visit the left subtree, then the root node, and finally the right subtree. This traversal results in nodes being visited in ascending order if the tree is a binary search tree.\n",
            "\n",
            "2. Preorder Traversal: In this traversal, we first visit the root node, then the left subtree, and finally the right subtree. This traversal is useful for creating a copy of the tree or for printing the tree in a specific format.\n",
            "\n",
            "3. Postorder Traversal: In this traversal, we first visit the left subtree, then the right subtree, and finally the root node. This traversal is useful for deleting the tree or for evaluating expressions in a tree.\n",
            "\n",
            "To traverse a binary tree, we can use recursive algorithms or iterative algorithms using stacks or queues. Here is an example of a recursive implementation of inorder traversal in Python:\n",
            "\n",
            "```python\n",
            "class Node:\n",
            "    def __init__(self, data):\n",
            "        self.data = data\n",
            "        self.left = None\n",
            "        self.right = None\n",
            "\n",
            "def inorder_traversal(node):\n",
            "    if node:\n",
            "        inorder_traversal(node.left)\n",
            "        print(node.data)\n",
            "        inorder_traversal(node.right)\n",
            "\n",
            "# Example usage:\n",
            "# Create a binary tree\n",
            "root = Node(1)\n",
            "root.left = Node(2)\n",
            "root.right = Node(3)\n",
            "root.left.left = Node(4)\n",
            "root.left.right = Node(5)\n",
            "\n",
            "# Traverse the binary tree in inorder\n",
            "inorder_traversal(root)\n",
            "```\n",
            "\n",
            "This will output:\n",
            "```\n",
            "4\n",
            "2\n",
            "5\n",
            "1\n",
            "3\n",
            "```\n",
            "\n",
            "You can modify the above code to implement preorder or postorder traversal by changing the order of the recursive calls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automatic Prompt Engineer"
      ],
      "metadata": {
        "id": "A5ayoeV_hlQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_request = f\"\"\" Can you craft a good prompt? CAn you include these elements to it? cake,cookies,milk and baking.\n",
        "# Ask the model to help you craft a good prompt. Ask for a prompt that includes all or some of the below:\n",
        "# - Subject\n",
        "# - Formality\n",
        "# - Endedness\n",
        "# - Reasoning Path\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "t5xnMDGChyML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Active Prompting"
      ],
      "metadata": {
        "id": "tQwpJ51dgvrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "# Give the model a moderately difficult mathematical word question.\n",
        "# You can ask the model to come up with one if you want to.\n",
        "# Copy the output to the cell below and repeat this process 4 more times.\n",
        "# Now, analyze the outputs altogether and count the number of different final answers.\n",
        "# The uncertainty value will be the number of different final answers divided by the total number of answers (5).\n",
        "# With this logic, higher uncertainty values mean the model is more uncertain of the answer.\n",
        "# Experiment with different levels of questions and different temperature values.\n",
        "\n",
        "generate a moderately difficult mathematical word question related to tempracture\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = get_cc(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "7F9kIrwahCOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18336860-6606-4d46-ff86-4db222ff9226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the temperature in Celsius if it is 68 degrees Fahrenheit?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_1 = \"\"\"\n",
        "What is the sum of the first 10 prime numbers?\n",
        "\"\"\"\n",
        "\n",
        "response_2 = \"\"\"\n",
        "What is the value of x in the equation 3x^2 + 5x - 2 = 0?\n",
        "\"\"\"\n",
        "\n",
        "response_3 = \"\"\"\n",
        "What is the sum of the first 10 prime numbers?\n",
        "\"\"\"\n",
        "\n",
        "response_4 = \"\"\"\n",
        "What is the sum of the first 10 prime numbers?\n",
        "\"\"\"\n",
        "\n",
        "response_5 = \"\"\"\n",
        "What is the temperature in Celsius if it is 68 degrees Fahrenheit?\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "iNdrxSualWLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Directional Stimulus Prompting\n"
      ],
      "metadata": {
        "id": "YZgghKyXjn7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "write a short article on statue of liberty and summarize it. include France, newyork city and copper\n",
        "# Give the model a short article and ask it to summarize it.\n",
        "# Then, ask it again, but provide a hint including contextual keywords from the article.\n",
        "# Compare the outputs and think about what it might take to automate this process.\n",
        "\"\"\"\n",
        "\n",
        "response = get_cc(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "FzVGnLS_kCCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0710530f-488d-4bdd-d700-5b29e8884f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Statue of Liberty is an iconic symbol of freedom and democracy, located in New York City. This colossal statue was a gift from France to the United States and was dedicated on October 28, 1886. Designed by French sculptor Frédéric Auguste Bartholdi, the statue is made of copper and stands at a height of 305 feet, including its pedestal. It depicts a robed female figure representing Libertas, the Roman goddess of freedom, holding a torch and a tabula ansata (a tablet evoking the law) inscribed with the date of the American Declaration of Independence. The statue has become a popular tourist attraction and a symbol of hope for immigrants arriving in America.\n",
            "\n",
            "Summary: The Statue of Liberty is a famous symbol of freedom and democracy located in New York City. It was a gift from France and is made of copper. Designed by Frédéric Auguste Bartholdi, the statue represents Libertas and holds a torch and a tablet with the date of the American Declaration of Independence.\n",
            "\n",
            "Hint: The article is about a famous symbol of freedom and democracy, gifted by one country to another. It is made of a specific material and is located in a specific city.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ReAct Prompting"
      ],
      "metadata": {
        "id": "XvGHXOz1ljtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\" You are a player in a text adventure game and i am the game. the scenario is i am in a room with a bed and a window. you have to attempt to leave the room via text commands.\n",
        "also explain its thought process (CoT).\n",
        "# Tell the model it is a player in a text adventure game.\n",
        "# Also tell the model that you, the user, are the game.\n",
        "# Give the model a scenario (ex: you are in a room with a bed and a window).\n",
        "# Ask the model to attempt to leave the room via text commands.\n",
        "# Also ask it to explain its thought process (CoT).\n",
        "# Challenge the model. Be the game!\n",
        "# Note: This may be better played via conversational model (use ChatGPT's webpage)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = get_cc(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "MO9Uf8Kqlo88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3934253-c338-4e50-e5a9-f5ff1efbd6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a player in a text adventure game. I, the user, am the game. Here's the scenario: You find yourself in a room with a bed and a window. Your objective is to attempt to leave the room using text commands. Please explain your thought process as you make your attempts.\n",
            "\n",
            "Player: Look around\n",
            "Game: You see a small room with a bed against one wall and a window on the opposite wall. There doesn't seem to be any other exits.\n",
            "\n",
            "Player: Examine the window\n",
            "Game: The window is closed but not locked. It provides a view of the outside world.\n",
            "\n",
            "Player: Open the window\n",
            "Game: You push the window open, allowing fresh air to enter the room.\n",
            "\n",
            "Player: Climb out of the window\n",
            "Game: As you attempt to climb out of the window, you realize it's too small for you to fit through. You're unable to leave the room this way.\n",
            "\n",
            "Player: Examine the bed\n",
            "Game: The bed is neatly made with clean sheets. It looks comfortable.\n",
            "\n",
            "Player: Search under the bed\n",
            "Game: You search under the bed and find nothing but dust bunnies and a few loose coins.\n",
            "\n",
            "Player: Move the bed\n",
            "Game: You try to move the bed, but it's too heavy to be easily shifted.\n",
            "\n",
            "Player: Check the walls for any hidden doors\n",
            "Game: You examine the walls carefully, feeling for any hidden switches or doors, but find nothing out of the ordinary.\n",
            "\n",
            "Player: Knock on the walls\n",
            "Game: You knock on the walls, hoping to find a hollow sound indicating a secret passage, but all you hear is a solid thud.\n",
            "\n",
            "Player: Lie down on the bed and think\n",
            "Game: You lie down on the bed, contemplating your situation. As you relax, an idea strikes you.\n",
            "\n",
            "Player: Push the bed against the window\n",
            "Game: You push the bed against the window, creating a makeshift platform to stand on.\n",
            "\n",
            "Player: Climb onto the bed and open the window again\n",
            "Game: You climb onto the bed and open the window once more, giving yourself a better view of the outside.\n",
            "\n",
            "Player: Jump out of the window\n",
            "Game: With the bed acting as a stepping stone, you jump out of the window and successfully leave the room.\n",
            "\n",
            "Player: Explain your thought process\n",
            "Game: Initially, I explored the room and assessed my surroundings. I tried to open the window and climb out, but it was too small. Then, I examined the bed and searched under it, but found nothing useful. Since there were no visible exits or hidden doors, I decided to think creatively. I realized that by moving the bed and using it as a platform, I could reach the window and jump out. This solution allowed me to successfully leave the room.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MM Prompting\n",
        "Unfortunately, multimodal prompting isn't publically available at the time of this notebook's production. However, there's interesting research currently being done regarding fine-tuning language models to interact with vision models - [here's](https://multimodal-react.github.io/) an interesting paper on this subject."
      ],
      "metadata": {
        "id": "wnXnjGr6sjxn"
      }
    }
  ]
}